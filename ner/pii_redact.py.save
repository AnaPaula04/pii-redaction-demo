def mask_ner_group(text: str, ents, group: str, token: str):
    """Replace all spans for a specific NER group with a token."""
    # Filter only the group we want (e.g., "LOC")
    sel = [e for e in ents if str(e.get("entity_group")) == group]
    # Replace from right to left so indices don't shift
    for e in sorted(sel, key=lambda x: int(x["start"]), reverse=True):
        start, end = int(e["start"]), int(e["end"])
        text = text[:start] + token + text[end:]
    return text, len(sel)

def clean_ents_for_json(ents):
    """Cast numpy/torch types to plain Python for JSON + masking."""
    cleaned = []
    for e in ents:
        e2 = dict(e)
        # normalize keys just in case
        if "entity_group" in e2 and isinstance(e2["entity_group"], bytes):
            e2["entity_group"] = e2["entity_group"].decode("utf-8", "ignore")
        if "score" in e2:
            try: e2["score"] = float(e2["score"])
            except: pass
        for k in ("start", "end"):
            if k in e2:
                try: e2[k] = int(e2[k])
                except: pass
        cleaned.append(e2)
    return cleaned
#!/usr/bin/env python3
"""
PII Redaction Demo: NER (Hugging Face) + regex masks
Usage (from project root):
  python -W ignore ner/pii_redact.py data/sample_sentences.txt
"""
import sys, re, json, pathlib, unicodedata
from collections import Counter
from transformers import pipeline

# --- Regex patterns (demo) ---
EMAIL_RE = re.compile(r'[\w\.-]+@[\w\.-]+\.\w+')
SSN_RE   = re.compile(r'\b\d{3}-\d{2}-\d{4}\b')
# Handles: (312) 555-0199, 312-555-0199, 312 555 0199, +1 312 555 0199, 312.555.0199
PHONE_RE = re.compile(r'(?:\+?1[\s.-]?)?(?:\(?\d{3}\)?[\s.-]*)\d{3}[\s.-]?\d{4}(?!\d)')

def preprocess_text(text: str) -> str:
    text = unicodedata.normalize("NFC", text)
    text = text.replace("\u2018", "'").replace("\u2019", "'").replace("\u201c", '"').replace("\u201d", '"')
    text = " ".join(text.split())
    return text

def mask_regex(text: str):
    counts = Counter()
    text, c = EMAIL_RE.subn("[EMAIL_REDACTED]", text); counts["EMAIL"] += c
    text, c = SSN_RE.subn("[SSN_REDACTED]", text);     counts["SSN"]   += c
    text, c = PHONE_RE.subn("[PHONE_REDACTED]", text); counts["PHONE"] += c
    return text, counts

def mask_ner_group(text: str, ents, group: str, token: str):
    sel = [e for e in ents if e.get("entity_group") == group]
    for e in sorted(sel, key=lambda x: x["start"], reverse=True):
        start, end = int(e["start"]), int(e["end"])
        text = text[:start] + token + text[end:]
    return text, len(sel)

def clean_ents_for_json(ents):
    cleaned = []
    for e in ents:
        e2 = dict(e)
        if "score" in e2:
            try: e2["score"] = float(e2["score"])
            except: pass
        for k in ("start","end"):
            if k in e2:
                try: e2[k] = int(e2[k])
                except: pass
        cleaned.append(e2)
    return cleaned

def main():
    if len(sys.argv) < 2:
        print("Usage: python -W ignore ner/pii_redact.py data/sample_sentences.txt")
        sys.exit(1)

    in_path = pathlib.Path(sys.argv[1])
    if not in_path.exists():
        print(f"Input file not found: {in_path}")
        sys.exit(1)

    lines = [ln.strip() for ln in in_path.read_text().splitlines() if ln.strip()]

    print("Loading NER model (dslim/bert-base-NER)...")
    nlp = pipeline("ner", model="dslim/bert-base-NER", aggregation_strategy="simple")

    report_path = in_path.parent / "entities_report.jsonl"
    out_path    = in_path.parent / "redacted_output.txt"

    totals = Counter()
    redacted_lines = []
    with report_path.open("w") as rep:
        for s in lines:
            s = preprocess_text(s)
            ents = nlp(s)
            ents_clean = clean_ents_for_json(ents)
            rep.write(json.dumps({"text": s, "entities": ents_clean}, ensure_ascii=False) + "\n")

            # 1) Regex masks
            masked, counts = mask_regex(s)
            totals.update(counts)

            # 2) NER masks for PERSON and LOC
            masked, c_per = mask_ner_group(masked, ents_clean, "PER", "[PERSON_REDACTED]")
            masked, c_loc = mask_ner_group(masked, ents_clean, "LOC", "[LOC_REDACTED]")
            totals["PERSON"] += c_per
            totals["LOC"]    += c_loc

            redacted_lines.append(masked)

    out_path.write_text("\n".join(redacted_lines))

    print("\n=== Done ===")
    print(f"- Entities report: {report_path}")
    print(f"- Redacted text : {out_path}")
    print("\nSummary (masked counts):")
    for k in ("PERSON","LOC","EMAIL","PHONE","SSN"):
        if totals[k]:
            print(f"  {k:7s}: {totals[k]}")
    if not any(totals.values()):
        print("  (no masks applied)")

if __name__ == "__main__":
    main()
#!/usr/bin/env python3
"""
PII Redaction Demo: NER (Hugging Face) + regex masks
Usage (from project root):
  python -W ignore ner/pii_redact.py data/sample_sentences.txt
"""
import sys, re, json, pathlib
from transformers import pipeline

# --- Regex patterns (demo) ---
EMAIL_RE = re.compile(r'[\w\.-]+@[\w\.-]+\.\w+')
SSN_RE   = re.compile(r'\b\d{3}-\d{2}-\d{4}\b')
# Handles: (312) 555-0199, 312-555-0199, 312 555 0199, +1 312 555 0199, 312.555.0199
PHONE_RE = re.compile(r'(?:\+?1[\s.-]?)?(?:\(?\d{3}\)?[\s.-]*)\d{3}[\s.-]?\d{4}(?!\d)')

def mask_regex(text: str) -> str:
    text = EMAIL_RE.sub("[EMAIL_REDACTED]", text)
    text = SSN_RE.sub("[SSN_REDACTED]", text)
    text = PHONE_RE.sub("[PHONE_REDACTED]", text)
    return text

def mask_ner(text: str, ents, groups=("PER",)) -> str:
    ents_sorted = sorted(
        [e for e in ents if e.get("entity_group") in groups],
        key=lambda e: e["start"],
        reverse=True,
    )
    for e in ents_sorted:
        start = int(e["start"]); end = int(e["end"])
        text = text[:start] + "[PERSON_REDACTED]" + text[end:]
    return text

def main():
    if len(sys.argv) < 2:
        print("Usage: python -W ignore ner/pii_redact.py data/sample_sentences.txt")
        sys.exit(1)

    in_path = pathlib.Path(sys.argv[1])
    if not in_path.exists():
        print(f"Input file not found: {in_path}")
        sys.exit(1)

    lines = [ln.strip() for ln in in_path.read_text().splitlines() if ln.strip()]

    print("Loading NER model (dslim/bert-base-NER)...")
    nlp = pipeline("ner", model="dslim/bert-base-NER", aggregation_strategy="simple")

    report_path = in_path.parent / "entities_report.jsonl"
    out_path    = in_path.parent / "redacted_output.txt"

    redacted_lines = []
    with report_path.open("w") as rep:
        for s in lines:
            ents = nlp(s)

            # JSON-safe cleanup (float32 -> float, spans -> int)
            ents_clean = []
            for e in ents:
                e2 = dict(e)
                if "score" in e2:
                    try: e2["score"] = float(e2["score"])
                    except: pass
                for k in ("start","end"):
                    if k in e2:
                        try: e2[k] = int(e2[k])
                        except: pass
                ents_clean.append(e2)

            rep.write(json.dumps({"text": s, "entities": ents_clean}, ensure_ascii=False) + "\n")

            masked = mask_regex(s)
            masked = mask_ner(masked, ents_clean, groups=("PER",))
            redacted_lines.append(masked)

    out_path.write_text("\n".join(redacted_lines))
    print("\n=== Done ===")
    print(f"- Entities report: {report_path}")
    print(f"- Redacted text : {out_path}")

if __name__ == "__main__":
    main()

